{% extends 'base.html.twig' %}
{% form_theme append _self %}

{% block title %}{{ append.vars.data.title }}{% endblock %}
{% block header_title %}
    <nav style="float: right">
        <a href="{{ path('app_vertexcrud_show', {pk: append.vars.data.pk}) }}" title="Voir"><i class="icon-eye"></i></a>
    </nav>
    {{ block('title') }}
{% endblock %}

{% block content %}
    <section class="form-prompt">
        {{ form(prompt) }}
    </section>
    <section x-data="llm">
        <div x-show="waiting" style="text-align: center"><i class="icon-spin3 animate-spin big-waiting"></i></div>
        <div x-show="content !== ''">
            <hgroup>
                <h2>Ce contenu généré s'ajoutera à {{ append.vars.data.title }}</h2>
                <h3>(Le formatage Markdown sera converti à la volée en formatage Wikitext)</h3>
            </hgroup>
            {{ form(append) }}
        </div>
    </section>
{% endblock %}

{% block _llm_output_append_generation_row %}
    {{ form_widget(form, {attr:{class:'pure-input-1'}}) }}
{% endblock %}

{% block javascripts %}
    {{ parent() }}
    <script type="application/json" id="ollama-payload">
        {{ payload|json_encode()|raw }}
    </script>
    <script type="module">
        import llmClient from 'ollama-client';

        Alpine.data('llm', () => {
            return llmClient('http://localhost:11434/api/chat', 'ollama-payload')
        })
    </script>
{% endblock %}

{% block stylesheets %}
    {{ parent() }}
    <style>
        .form-prompt fieldset {
            line-height: 2.2em;
        }
    </style>
{% endblock %}
